[2025-07-06T10:01:55.671+0000] {logging_mixin.py:150} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/sqlalchemy.py:124 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-06T10:01:55.679+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: customer_activity_analysis.transform_data scheduled__2025-06-05T00:00:00+00:00 [queued]>
[2025-07-06T10:01:55.685+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: customer_activity_analysis.transform_data scheduled__2025-06-05T00:00:00+00:00 [queued]>
[2025-07-06T10:01:55.685+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 2
[2025-07-06T10:01:55.695+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonOperator): transform_data> on 2025-06-05 00:00:00+00:00
[2025-07-06T10:01:55.704+0000] {standard_task_runner.py:57} INFO - Started process 306 to run task
[2025-07-06T10:01:55.706+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'customer_activity_analysis', 'transform_data', 'scheduled__2025-06-05T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/customer_activity_dag.py', '--cfg-path', '/tmp/tmpzk9t2ydd']
[2025-07-06T10:01:55.708+0000] {standard_task_runner.py:85} INFO - Job 3: Subtask transform_data
[2025-07-06T10:01:55.720+0000] {logging_mixin.py:150} WARNING - /home/***/.local/lib/python3.7/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-06T10:01:55.749+0000] {task_command.py:410} INFO - Running <TaskInstance: customer_activity_analysis.transform_data scheduled__2025-06-05T00:00:00+00:00 [running]> on host 815e07275dfd
[2025-07-06T10:01:55.758+0000] {logging_mixin.py:150} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/sqlalchemy.py:124 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-06T10:01:55.812+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='customer_activity_analysis' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2025-06-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-05T00:00:00+00:00'
[2025-07-06T10:01:55.813+0000] {taskinstance.py:1824} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
TypeError: transform() missing 2 required positional arguments: 'profit_table' and 'date'
[2025-07-06T10:01:55.819+0000] {taskinstance.py:1350} INFO - Marking task as UP_FOR_RETRY. dag_id=customer_activity_analysis, task_id=transform_data, execution_date=20250605T000000, start_date=20250706T100155, end_date=20250706T100155
[2025-07-06T10:01:55.828+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 3 for task transform_data (transform() missing 2 required positional arguments: 'profit_table' and 'date'; 306)
[2025-07-06T10:01:55.878+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 1
[2025-07-06T10:01:55.898+0000] {taskinstance.py:2653} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-06T17:07:44.285+0000] {logging_mixin.py:150} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/sqlalchemy.py:124 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-06T17:07:44.294+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: customer_activity_analysis.transform_data scheduled__2025-06-05T00:00:00+00:00 [queued]>
[2025-07-06T17:07:44.300+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: customer_activity_analysis.transform_data scheduled__2025-06-05T00:00:00+00:00 [queued]>
[2025-07-06T17:07:44.300+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 2
[2025-07-06T17:07:44.313+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonOperator): transform_data> on 2025-06-05 00:00:00+00:00
[2025-07-06T17:07:44.322+0000] {standard_task_runner.py:57} INFO - Started process 241 to run task
[2025-07-06T17:07:44.324+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'customer_activity_analysis', 'transform_data', 'scheduled__2025-06-05T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/customer_activity_dag.py', '--cfg-path', '/tmp/tmp37v7ioql']
[2025-07-06T17:07:44.326+0000] {standard_task_runner.py:85} INFO - Job 5: Subtask transform_data
[2025-07-06T17:07:44.339+0000] {logging_mixin.py:150} WARNING - /home/***/.local/lib/python3.7/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-06T17:07:44.370+0000] {task_command.py:410} INFO - Running <TaskInstance: customer_activity_analysis.transform_data scheduled__2025-06-05T00:00:00+00:00 [running]> on host c00985d5f7a4
[2025-07-06T17:07:44.380+0000] {logging_mixin.py:150} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/sqlalchemy.py:124 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-06T17:07:44.443+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='your_email@example.com' AIRFLOW_CTX_DAG_OWNER='Daniil' AIRFLOW_CTX_DAG_ID='customer_activity_analysis' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2025-06-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-05T00:00:00+00:00'
[2025-07-06T17:07:53.933+0000] {logging_mixin.py:150} INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!Debug data saved to /opt/***/data/debug_data.csv
[2025-07-06T17:07:53.934+0000] {logging_mixin.py:150} INFO - Processing data for date: 2025-06-05
[2025-07-06T17:07:53.934+0000] {logging_mixin.py:150} INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!Received date type: <class 'str'>, value: 2025-06-05
[2025-07-06T17:07:53.989+0000] {logging_mixin.py:150} WARNING -   0%|          | 0/10 [00:00<?, ?it/s]
[2025-07-06T17:07:53.990+0000] {logging_mixin.py:150} WARNING -   0%|          | 0/10 [00:00<?, ?it/s]
[2025-07-06T17:07:53.990+0000] {logging_mixin.py:150} INFO - Error in transform: Wrong number of items passed 20, placement implies 1
[2025-07-06T17:07:53.990+0000] {taskinstance.py:1824} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py", line 3361, in get_loc
    return self._engine.get_loc(casted_key)
  File "pandas/_libs/index.pyx", line 76, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 108, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'flag_a'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/frame.py", line 3751, in _set_item_mgr
    loc = self._info_axis.get_loc(key)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py", line 3363, in get_loc
    raise KeyError(key) from err
KeyError: 'flag_a'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/customer_activity_dag.py", line 95, in transform_data
    result = transform(profit_table=df, date=date_str)
  File "/opt/airflow/dags/customer_activity_dag.py", line 56, in transform
    ).astype(int)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/frame.py", line 3602, in __setitem__
    self._set_item_frame_value(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/frame.py", line 3742, in _set_item_frame_value
    self._set_item_mgr(key, arraylike)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/frame.py", line 3754, in _set_item_mgr
    self._mgr.insert(len(self._info_axis), key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py", line 1162, in insert
    block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1))
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/internals/blocks.py", line 1937, in new_block
    check_ndim(values, placement, ndim)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/internals/blocks.py", line 1980, in check_ndim
    f"Wrong number of items passed {len(values)}, "
ValueError: Wrong number of items passed 20, placement implies 1
[2025-07-06T17:07:54.005+0000] {taskinstance.py:1350} INFO - Marking task as UP_FOR_RETRY. dag_id=customer_activity_analysis, task_id=transform_data, execution_date=20250605T000000, start_date=20250706T170744, end_date=20250706T170754
[2025-07-06T17:07:54.021+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 5 for task transform_data (Wrong number of items passed 20, placement implies 1; 241)
[2025-07-06T17:07:54.094+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 1
[2025-07-06T17:07:54.114+0000] {taskinstance.py:2653} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-06T19:16:38.034+0000] {logging_mixin.py:150} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/sqlalchemy.py:124 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-06T19:16:38.043+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: customer_activity_analysis.transform_data scheduled__2025-06-05T00:00:00+00:00 [queued]>
[2025-07-06T19:16:38.050+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: customer_activity_analysis.transform_data scheduled__2025-06-05T00:00:00+00:00 [queued]>
[2025-07-06T19:16:38.050+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 2
[2025-07-06T19:16:38.062+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonOperator): transform_data> on 2025-06-05 00:00:00+00:00
[2025-07-06T19:16:38.070+0000] {standard_task_runner.py:57} INFO - Started process 358 to run task
[2025-07-06T19:16:38.072+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'customer_activity_analysis', 'transform_data', 'scheduled__2025-06-05T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/customer_activity_dag.py', '--cfg-path', '/tmp/tmp851zyv1v']
[2025-07-06T19:16:38.074+0000] {standard_task_runner.py:85} INFO - Job 5: Subtask transform_data
[2025-07-06T19:16:38.085+0000] {logging_mixin.py:150} WARNING - /home/***/.local/lib/python3.7/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-06T19:16:38.118+0000] {task_command.py:410} INFO - Running <TaskInstance: customer_activity_analysis.transform_data scheduled__2025-06-05T00:00:00+00:00 [running]> on host 7a17032e36f4
[2025-07-06T19:16:38.127+0000] {logging_mixin.py:150} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/sqlalchemy.py:124 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-06T19:16:38.188+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='ds_const@mail.ru' AIRFLOW_CTX_DAG_OWNER='Daniil' AIRFLOW_CTX_DAG_ID='customer_activity_analysis' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2025-06-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-05T00:00:00+00:00'
[2025-07-06T19:16:38.197+0000] {logging_mixin.py:150} INFO - /opt/***/shared_tmp/extract_scheduled__2025-06-05T00:00:00+00:00.parquet
[2025-07-06T19:16:38.425+0000] {logging_mixin.py:150} INFO - Received date type: <class 'str'>, value: 2025-06-05
[2025-07-06T19:16:38.486+0000] {logging_mixin.py:150} INFO - Debug data saved to /opt/***/data/debug_data.parquet
[2025-07-06T19:16:38.489+0000] {logging_mixin.py:150} WARNING - Generating flags:   0%|          | 0/10 [00:00<?, ?it/s]
[2025-07-06T19:16:38.495+0000] {logging_mixin.py:150} WARNING - Generating flags: 100%|##########| 10/10 [00:00<00:00, 1775.67it/s]
[2025-07-06T19:16:38.505+0000] {python.py:183} INFO - Done. Returned value was: /opt/***/shared_tmp/transform_scheduled__2025-06-05T00:00:00+00:00.parquet
[2025-07-06T19:16:38.535+0000] {taskinstance.py:1350} INFO - Marking task as SUCCESS. dag_id=customer_activity_analysis, task_id=transform_data, execution_date=20250605T000000, start_date=20250706T191638, end_date=20250706T191638
[2025-07-06T19:16:38.608+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2025-07-06T19:16:38.628+0000] {taskinstance.py:2653} INFO - 1 downstream tasks scheduled from follow-on schedule check
